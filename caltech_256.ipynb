{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fsamir/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/fsamir/anaconda3/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "root_dir = '../input/caltech256/256_ObjectCategories'\n",
    "# get all the folder paths\n",
    "all_paths = os.listdir(root_dir)\n",
    "\n",
    "# create a DataFrame\n",
    "data = pd.DataFrame()\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "counter = 0\n",
    "for folder_path in tqdm(all_paths, total=len(all_paths)):\n",
    "    # get all the image names in the particular folder\n",
    "    image_paths = os.listdir(f\"{root_dir}/{folder_path}\")\n",
    "    # get the folder as label\n",
    "    label = folder_path.split('.')[-1]\n",
    "    \n",
    "    if label == 'clutter':\n",
    "        continue\n",
    "\n",
    "    # save image paths in the DataFrame\n",
    "    for image_path in image_paths:\n",
    "        if image_path.split('.')[-1] == 'jpg':\n",
    "            data.loc[counter, 'image_path'] = f\"{root_dir}/{folder_path}/{image_path}\"\n",
    "            labels.append(label)\n",
    "            counter += 1\n",
    "\n",
    "labels = np.array(labels)\n",
    "# one-hot encode the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "# add the image labels to the dataframe\n",
    "for i in range(len(labels)):\n",
    "    index = np.argmax(labels[i])\n",
    "    data.loc[i, 'target'] = int(index)\n",
    "    \n",
    "# shuffle the dataset\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of labels or classes: {len(lb.classes_)}\")\n",
    "print(f\"The first one hot encoded labels: {labels[0]}\")\n",
    "print(f\"Mapping the first one hot encoded label to its category: {lb.classes_[0]}\")\n",
    "print(f\"Total instances: {len(data)}\")\n",
    " \n",
    "# save as CSV file\n",
    "data.to_csv('data.csv', index=False)\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258/258 [00:00<00:00, 22363.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "def get_labels():\n",
    "    labels = []\n",
    "    root_dir = 'data/256_ObjectCategories'\n",
    "# get all the folder paths\n",
    "    all_paths = os.listdir(root_dir)\n",
    "    for folder_path in tqdm(all_paths, total=len(all_paths)):\n",
    "    # get all the image names in the particular folder\n",
    "        image_paths = os.listdir(f\"{root_dir}/{folder_path}\")\n",
    "        # get the folder as label\n",
    "        label = folder_path.split('.')[-1]\n",
    "        \n",
    "        if label == 'clutter':\n",
    "            continue\n",
    "\n",
    "        # save image paths in the DataFrame\n",
    "        for _ in image_paths:\n",
    "            labels.append(label)\n",
    "    return labels\n",
    "        \n",
    "def get_mapping_label_ind_to_concept(labels):\n",
    "    labels = np.array(labels)\n",
    "# one-hot encode the labels\n",
    "    lb = LabelBinarizer()\n",
    "    labels_binarized = lb.fit_transform(labels)\n",
    "\n",
    "    # add the image labels_binarized to the dataframe\n",
    "    label_ind_to_concept_map = {}\n",
    "    for i in range(len(labels_binarized)):\n",
    "        index = np.argmax(labels_binarized[i])\n",
    "        label_ind_to_concept_map[index] = labels[i]\n",
    "    return label_ind_to_concept_map\n",
    "\n",
    "label_ind_to_concept_map = get_mapping_label_ind_to_concept(get_labels())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{97: 'guitar-pick', 22: 'buddha-101', 174: 'refrigerator', 250: 'windmill', 71: 'fighter-jet', 84: 'galaxy', 253: 'yarmulke', 118: 'ice-cream-cone', 79: 'french-horn', 25: 'cactus', 144: 'microscope', 13: 'birdbath', 205: 'steering-wheel', 117: 'ibis-101', 182: 'scorpion-101', 146: 'minaret', 177: 'rotary-phone', 197: 'socks', 88: 'golden-gate-bridge', 237: 'tripod', 233: 'treadmill', 162: 'people', 81: 'frisbee', 115: 'human-skeleton', 207: 'sunflower-101', 210: 'swan', 78: 'football-helmet', 255: 'zebra', 244: 'washing-machine', 220: 'tennis-ball', 116: 'hummingbird', 95: 'grasshopper', 49: 'conch', 228: 'tombstone', 72: 'fire-extinguisher', 145: 'microwave', 215: 'tambourine', 201: 'spider', 136: 'lightning', 43: 'coffin', 101: 'harp', 165: 'picnic-table', 124: 'kangaroo-101', 65: 'elephant-101', 246: 'waterfall', 137: 'llama-101', 185: 'self-propelled-lawn-mower', 231: 'tower-pisa', 44: 'coin', 130: 'laptop-101', 122: 'jesus-christ', 209: 'sushi', 8: 'bathtub', 67: 'ewer-101', 196: 'soccer-ball', 213: 'syringe', 75: 'fireworks', 148: 'motorbikes-101', 152: 'necktie', 208: 'superman', 108: 'horse', 0: 'airplanes-101', 134: 'light-house', 94: 'grapes', 77: 'floppy-disk', 34: 'cd', 105: 'helicopter-101', 187: 'sheet-music', 23: 'bulldozer', 40: 'chopsticks', 32: 'car-tire', 26: 'cake', 56: 'dice', 112: 'hot-tub', 16: 'boom-box', 1: 'ak47', 86: 'giraffe', 132: 'leopards-101', 48: 'computer-mouse', 241: 'unicorn', 19: 'boxing-glove', 54: 'desk-globe', 222: 'tennis-racket', 218: 'teepee', 12: 'binoculars', 39: 'chimp', 203: 'stained-glass', 29: 'cannon', 243: 'video-projector', 85: 'gas-pump', 17: 'bowling-ball', 157: 'palm-tree', 104: 'head-phones', 219: 'telephone-box', 114: 'house-fly', 70: 'fern', 169: 'praying-mantis', 153: 'octopus', 62: 'dumb-bell', 141: 'mattress', 7: 'bat', 192: 'snail', 24: 'butterfly', 74: 'fire-truck', 109: 'horseshoe-crab', 217: 'teddy-bear', 204: 'starfish-101', 143: 'menorah-101', 170: 'pyramid', 45: 'comet', 91: 'goose', 33: 'cartman', 216: 'teapot', 103: 'hawksbill-101', 92: 'gorilla', 238: 'tuning-fork', 111: 'hot-dog', 15: 'bonsai-101', 3: 'backpack', 245: 'watch-101', 166: 'playing-card', 224: 'theodolite', 140: 'mars', 47: 'computer-monitor', 60: 'drinking-straw', 55: 'diamond-ring', 21: 'breadmaker', 149: 'mountain-bike', 200: 'speed-boat', 164: 'photocopier', 80: 'fried-egg', 82: 'frog', 234: 'triceratops', 106: 'hibiscus', 214: 't-shirt', 184: 'segway', 87: 'goat', 179: 'saddle', 188: 'skateboard', 133: 'license-plate', 58: 'dolphin-101', 11: 'billiards', 99: 'hammock', 180: 'saturn', 52: 'cowboy-hat', 181: 'school-bus', 37: 'chandelier-101', 226: 'toaster', 41: 'cockroach', 93: 'grand-piano-101', 4: 'baseball-bat', 46: 'computer-keyboard', 76: 'flashlight', 66: 'elk', 178: 'roulette-wheel', 236: 'trilobite-101', 90: 'golf-ball', 232: 'traffic-light', 127: 'killer-whale', 129: 'ladder', 36: 'cereal-box', 186: 'sextant', 10: 'beer-mug', 150: 'mushroom', 142: 'megaphone', 202: 'spoon', 59: 'doorknob', 159: 'paperclip', 212: 'sword', 229: 'top-hat', 30: 'canoe', 154: 'ostrich', 191: 'smokestack', 168: 'pram', 248: 'welding-mask', 123: 'joy-stick', 183: 'screwdriver', 121: 'iris', 138: 'mailbox', 242: 'vcr', 98: 'hamburger', 31: 'car-side-101', 172: 'radio-telescope', 28: 'camel', 125: 'kayak', 128: 'knife', 155: 'owl', 227: 'tomato', 96: 'greyhound', 193: 'snake', 230: 'touring-bike', 221: 'tennis-court', 131: 'lathe', 73: 'fire-hydrant', 190: 'skyscraper', 63: 'eiffel-tower', 14: 'blimp', 35: 'centipede', 102: 'harpsichord', 147: 'minotaur', 247: 'watermelon', 176: 'rifle', 254: 'yo-yo', 113: 'hourglass', 194: 'sneaker', 211: 'swiss-army-knife', 161: 'penguin', 249: 'wheelbarrow', 240: 'umbrella-101', 61: 'duck', 27: 'calculator', 160: 'pci-card', 18: 'bowling-pin', 69: 'faces-easy-101', 5: 'baseball-glove', 171: 'raccoon', 206: 'stirrups', 100: 'harmonica', 139: 'mandolin', 173: 'rainbow', 235: 'tricycle', 20: 'brain-101', 68: 'eyeglasses', 53: 'crab-101', 2: 'american-flag', 195: 'snowmobile', 156: 'palm-pilot', 120: 'ipod', 83: 'frying-pan', 110: 'hot-air-balloon', 9: 'bear', 223: 'tennis-shoes', 151: 'mussels', 198: 'soda-can', 239: 'tweezer', 119: 'iguana', 199: 'spaghetti', 42: 'coffee-mug', 50: 'cormorant', 189: 'skunk', 175: 'revolver-101', 89: 'goldfish', 135: 'lightbulb', 252: 'xylophone', 57: 'dog', 167: 'porcupine', 38: 'chess-board', 163: 'pez-dispenser', 251: 'wine-bottle', 64: 'electric-guitar-101', 107: 'homer-simpson', 225: 'toad', 158: 'paper-shredder', 51: 'covered-wagon', 126: 'ketch-101', 6: 'basketball-hoop'}\n"
     ]
    }
   ],
   "source": [
    "print(label_ind_to_concept_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset.py\n",
    "\n",
    "import albumentations\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# custom dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels=None, tfms=None):\n",
    "        self.X = images\n",
    "        self.y = labels\n",
    "\n",
    "        # apply augmentations\n",
    "        if tfms == 0: # if validating\n",
    "            self.aug = albumentations.Compose([\n",
    "                albumentations.Resize(224, 224, always_apply=True),\n",
    "            ])\n",
    "        else: # if training\n",
    "            self.aug = albumentations.Compose([\n",
    "                albumentations.Resize(224, 224, always_apply=True),\n",
    "                albumentations.HorizontalFlip(p=0.5),\n",
    "                albumentations.ShiftScaleRotate(\n",
    "                    shift_limit=0.3,\n",
    "                    scale_limit=0.3,\n",
    "                    rotate_limit=15,\n",
    "                    p=0.5\n",
    "                ),\n",
    "            ])\n",
    "         \n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image = Image.open(self.X[i])\n",
    "        image = image.convert('RGB')\n",
    "        image = self.aug(image=np.array(image))['image']\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        label = self.y[i]\n",
    "        return {\n",
    "            'image': torch.tensor(image, dtype=torch.float), \n",
    "            'target': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import pretrainedmodels\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, pretrained, requires_grad):\n",
    "        super(ResNet50, self).__init__()\n",
    "        if pretrained is True:\n",
    "            self.model = pretrainedmodels.__dict__['resnet50'](pretrained='imagenet')\n",
    "        else:\n",
    "            self.model = pretrainedmodels.__dict__['resnet50'](pretrained=None)\n",
    "            \n",
    "        if requires_grad == True:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif requires_grad == False:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.l0 = nn.Linear(2048, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, _, _, _ = x.shape\n",
    "        x = self.model.features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)\n",
    "        l0 = self.l0(x)\n",
    "        return l0\n",
    "\n",
    "model = ResNet50(pretrained=True, requires_grad=False)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import model\n",
    "from dataset import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# get the dataset ready\n",
    "df = pd.read_csv('data.csv')\n",
    "X = df.image_path.values # image paths\n",
    "y = df.target.values # targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = ImageDataset(X, y, tfms=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Iterable\n",
    "\n",
    "\n",
    "def collate_imgs(img_dicts: Iterable[Dict]):\n",
    "    img_tensors = [img_dict['image'] for img_dict in img_dicts]\n",
    "    label_tensors = [img_dict['target'] for img_dict in img_dicts] \n",
    "\n",
    "    batch_image_tensor = torch.stack(img_tensors)\n",
    "    batch_label_tensor = torch.stack(label_tensors)\n",
    "\n",
    "    return batch_image_tensor, batch_label_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(image_data, 128, shuffle=True, collate_fn=collate_imgs )\n",
    "image_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feats = []\n",
    "labels = []\n",
    "for batch_X, batch_y in iter(dataloader):\n",
    "    feats.append(model(batch_X.cuda()).cpu())\n",
    "    labels.append(batch_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = torch.cat(feats, dim=0)\n",
    "all_labels = torch.cat(labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_text = [label_ind_to_concept_map[label.item()] for label in all_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_feats, 'results/all_feats.pt')\n",
    "torch.save(all_labels, 'results/all_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"results/all_labels_text.pkl\", \"wb\") as pkl_f:\n",
    "    pickle.dump(all_labels_text, pkl_f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4ebfc88ccd97cb231efe00c7198020b2ae0235bcff1ce31852dbbe06876d933"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
